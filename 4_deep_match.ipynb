{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数值特征\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm as tqdm\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_data_dict = {}\n",
    "with open('data/raw_data/train.json', 'r') as f:\n",
    "    for line in f:\n",
    "        raw = eval(str(json.loads(line)).lower())\n",
    "        train_data.append(raw)\n",
    "        #train_data_dict[raw['text_id']] = raw\n",
    "kb = {}\n",
    "with open('data/raw_data/kb_data', 'r') as f:\n",
    "    for line in f:\n",
    "        item = eval(str(json.loads(line)).lower())\n",
    "        kb[item['subject_id']] = item\n",
    "            \n",
    "name_id = {}\n",
    "for kb_id in kb:\n",
    "    for item in kb[kb_id]['alias']:\n",
    "        if item not in name_id:\n",
    "            name_id[item] = [kb_id]\n",
    "        else:\n",
    "            name_id[item].append(kb_id)\n",
    "    if kb[kb_id]['subject'] not in name_id:\n",
    "        name_id[kb[kb_id]['subject']] = [kb_id]\n",
    "    else:\n",
    "        name_id[kb[kb_id]['subject']].append(kb_id)\n",
    "for id in name_id:\n",
    "    name_id[id] = sorted(list(set(name_id[id])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/step1.pkl')\n",
    "test_data = pd.read_pickle('data/step1_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         257734\n",
       "1         257735\n",
       "2         257735\n",
       "3         257735\n",
       "4         257735\n",
       "5         257735\n",
       "6         257735\n",
       "7         257735\n",
       "8         257735\n",
       "9         257735\n",
       "10        257736\n",
       "11        257736\n",
       "12        257736\n",
       "13        257736\n",
       "14        257736\n",
       "15        257736\n",
       "16        257736\n",
       "17        257736\n",
       "18        257737\n",
       "19        257737\n",
       "20        257737\n",
       "21        257737\n",
       "22        257737\n",
       "23        257737\n",
       "24        257737\n",
       "25        257737\n",
       "26        257737\n",
       "27        257737\n",
       "28        257737\n",
       "29        257737\n",
       "           ...  \n",
       "764187    353507\n",
       "764188    353507\n",
       "764189    353507\n",
       "764190    353507\n",
       "764191    353507\n",
       "764192    353507\n",
       "764193    353507\n",
       "764194    353508\n",
       "764195    353508\n",
       "764196    353508\n",
       "764197    353508\n",
       "764198    353508\n",
       "764199    353508\n",
       "764200    353508\n",
       "764201    353508\n",
       "764202    353508\n",
       "764203    353508\n",
       "764204    353508\n",
       "764205    353508\n",
       "764206    353508\n",
       "764207    353508\n",
       "764208    353508\n",
       "764209    353508\n",
       "764210    353508\n",
       "764211    353508\n",
       "764212    353508\n",
       "764213    353508\n",
       "764214    353508\n",
       "764215    353508\n",
       "764216    353509\n",
       "Name: m_id, Length: 764217, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['m_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_match = np.load('model_type/deep_match.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.1322297e-01, 9.6259850e-01, 9.9584371e-01, ..., 8.1027893e-04,\n",
       "       1.5532824e-02, 9.5632831e-03], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_match[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['deep_match'] = train_match[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_match = np.load('model_type/deep_match_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3821085, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = int(test_match.shape[0]/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_vector = []\n",
    "for i in range(5):\n",
    "    mention_vector.append(test_match[i*count:(i+1)*count,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_vector = sum(mention_vector)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(764217, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['deep_match'] = mention_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text_id', 'kb_id', 'train_mention', 'label', 'num_attrs',\n",
       "       'num_abstract_words', 'num_alias', 'm_id', 'num_candidates',\n",
       "       'mention_equal_subject', 'shuminghao', 'entity_common', 'len_mention',\n",
       "       'mention_start', 'create_works', 'mention_end', 'end_with_point',\n",
       "       'end_with_line', 'end_with_line2', 'end_with_shuminghao', 'works_match',\n",
       "       'numerical_0', 'numerical_1', 'numerical_2', 'numerical_3',\n",
       "       'numerical_4', 'numerical_5', 'numerical_6', 'numerical_7',\n",
       "       'numerical_8', 'numerical_9', 'numerical_10', 'numerical_11',\n",
       "       'numerical_12', 'numerical_13', 'numerical_14', 'type',\n",
       "       'type_label_mean', 'type_label_count', 'deep_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['label']= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhukaihua/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "data= data.append(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_rank = ['deep_match']\n",
    "data_all = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in to_rank:\n",
    "    data_group = data_all.groupby('m_id')[f].rank(ascending=False)\n",
    "    data_all['m_rank_'+f] = data_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/zhukaihua/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(to_rank):\n",
    "    data_group = data_all.groupby('m_id')[f].agg({'mid_'+f+'_var':'var','mid_'+f+'_mean':'mean',\n",
    "                                                  'mid_'+f+'_max':'max','mid_'+f+'_min':'min'})\n",
    "    data_all = data_all.merge(data_group,on='m_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_0\n",
      "numerical_1\n",
      "numerical_10\n",
      "numerical_11\n",
      "numerical_12\n",
      "numerical_13\n",
      "numerical_14\n",
      "numerical_2\n",
      "numerical_3\n",
      "numerical_4\n",
      "numerical_5\n",
      "numerical_6\n",
      "numerical_7\n",
      "numerical_8\n",
      "numerical_9\n",
      "type_label_count\n",
      "type_label_mean\n",
      "m_rank_deep_match\n"
     ]
    }
   ],
   "source": [
    "for item in data_all.columns:\n",
    "    if data_all.dtypes[item]=='float64':\n",
    "        print(item)\n",
    "        data_all[item] = data_all[item].astype('float32')\n",
    "    if data_all.dtypes[item]=='int64':\n",
    "        data_all[item] = data_all[item].astype('int32')\n",
    "    if data_all.dtypes[item]=='bool':\n",
    "        data_all[item] = data_all[item].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_works</th>\n",
       "      <th>deep_match</th>\n",
       "      <th>end_with_line</th>\n",
       "      <th>end_with_line2</th>\n",
       "      <th>end_with_point</th>\n",
       "      <th>end_with_shuminghao</th>\n",
       "      <th>entity_common</th>\n",
       "      <th>kb_id</th>\n",
       "      <th>label</th>\n",
       "      <th>len_mention</th>\n",
       "      <th>...</th>\n",
       "      <th>train_mention</th>\n",
       "      <th>type</th>\n",
       "      <th>type_label_count</th>\n",
       "      <th>type_label_mean</th>\n",
       "      <th>works_match</th>\n",
       "      <th>m_rank_deep_match</th>\n",
       "      <th>mid_deep_match_var</th>\n",
       "      <th>mid_deep_match_mean</th>\n",
       "      <th>mid_deep_match_max</th>\n",
       "      <th>mid_deep_match_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.913223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>130287</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>南京南站</td>\n",
       "      <td>place</td>\n",
       "      <td>27241.0</td>\n",
       "      <td>0.336478</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.937911</td>\n",
       "      <td>0.962599</td>\n",
       "      <td>0.913223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.962599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>311223</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>南京南站</td>\n",
       "      <td>place</td>\n",
       "      <td>27241.0</td>\n",
       "      <td>0.336478</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.937911</td>\n",
       "      <td>0.962599</td>\n",
       "      <td>0.913223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.995844</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>341096</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>高铁</td>\n",
       "      <td>thing</td>\n",
       "      <td>499598.0</td>\n",
       "      <td>0.072104</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995844</td>\n",
       "      <td>0.995844</td>\n",
       "      <td>0.995844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>130287</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>南京南站</td>\n",
       "      <td>place</td>\n",
       "      <td>27241.0</td>\n",
       "      <td>0.336478</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.940003</td>\n",
       "      <td>0.963922</td>\n",
       "      <td>0.916084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.963922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>311223</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>南京南站</td>\n",
       "      <td>place</td>\n",
       "      <td>27241.0</td>\n",
       "      <td>0.336478</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.940003</td>\n",
       "      <td>0.963922</td>\n",
       "      <td>0.916084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   create_works  deep_match  end_with_line  end_with_line2  end_with_point  \\\n",
       "0             0    0.913223              0               0               0   \n",
       "1             0    0.962599              0               0               0   \n",
       "2             0    0.995844              0               0               0   \n",
       "3             0    0.916084              0               0               0   \n",
       "4             0    0.963922              0               0               0   \n",
       "\n",
       "   end_with_shuminghao  entity_common   kb_id  label  len_mention  ...  \\\n",
       "0                    0              4  130287      0            4  ...   \n",
       "1                    0              4  311223      1            4  ...   \n",
       "2                    0              1  341096      1            2  ...   \n",
       "3                    0              4  130287      0            4  ...   \n",
       "4                    0              4  311223      1            4  ...   \n",
       "\n",
       "   train_mention   type  type_label_count  type_label_mean  works_match  \\\n",
       "0           南京南站  place           27241.0         0.336478            1   \n",
       "1           南京南站  place           27241.0         0.336478            1   \n",
       "2             高铁  thing          499598.0         0.072104            1   \n",
       "3           南京南站  place           27241.0         0.336478            1   \n",
       "4           南京南站  place           27241.0         0.336478            1   \n",
       "\n",
       "   m_rank_deep_match  mid_deep_match_var  mid_deep_match_mean  \\\n",
       "0                2.0            0.001219             0.937911   \n",
       "1                1.0            0.001219             0.937911   \n",
       "2                1.0                 NaN             0.995844   \n",
       "3                2.0            0.001144             0.940003   \n",
       "4                1.0            0.001144             0.940003   \n",
       "\n",
       "   mid_deep_match_max  mid_deep_match_min  \n",
       "0            0.962599            0.913223  \n",
       "1            0.962599            0.913223  \n",
       "2            0.995844            0.995844  \n",
       "3            0.963922            0.916084  \n",
       "4            0.963922            0.916084  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all.iloc[0:train_size,:]\n",
    "test_data = data_all.iloc[train_size:,:]\n",
    "data.reset_index(drop=True,inplace=True)\n",
    "test_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('data/step4.pkl')\n",
    "test_data.to_pickle('data/step4_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
