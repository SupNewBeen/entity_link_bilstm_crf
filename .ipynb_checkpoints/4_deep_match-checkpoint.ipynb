{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数值特征\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm as tqdm\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_data_dict = {}\n",
    "with open('data/raw_data/train.json', 'r') as f:\n",
    "    for line in f:\n",
    "        raw = eval(str(json.loads(line)).lower())\n",
    "        train_data.append(raw)\n",
    "        #train_data_dict[raw['text_id']] = raw\n",
    "kb = {}\n",
    "with open('data/raw_data/kb_data', 'r') as f:\n",
    "    for line in f:\n",
    "        item = eval(str(json.loads(line)).lower())\n",
    "        kb[item['subject_id']] = item\n",
    "            \n",
    "name_id = {}\n",
    "for kb_id in kb:\n",
    "    for item in kb[kb_id]['alias']:\n",
    "        if item not in name_id:\n",
    "            name_id[item] = [kb_id]\n",
    "        else:\n",
    "            name_id[item].append(kb_id)\n",
    "    if kb[kb_id]['subject'] not in name_id:\n",
    "        name_id[kb[kb_id]['subject']] = [kb_id]\n",
    "    else:\n",
    "        name_id[kb[kb_id]['subject']].append(kb_id)\n",
    "for id in name_id:\n",
    "    name_id[id] = sorted(list(set(name_id[id])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90000/90000 [00:12<00:00, 7074.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# 提取candidate候选特征\n",
    "kb_column = []\n",
    "train_column = []\n",
    "text_id = []\n",
    "label_colum = []\n",
    "num_attrs = []\n",
    "num_abstract_words = []\n",
    "num_alias = []\n",
    "m_id = 0\n",
    "m_id_list = []\n",
    "entity_common = []\n",
    "len_mention = []\n",
    "mention_start = []\n",
    "numerical_f = []\n",
    "create_works = []\n",
    "for s in tqdm(train_data):\n",
    "    mention_ner = s['mention_data']\n",
    "    m_list = []\n",
    "    for m in mention_ner:\n",
    "        m_list.append(m['mention'])\n",
    "    for m in mention_ner:\n",
    "        if m['mention'] not in name_id : # 不能注销，因为有些实体没有or m['kb_id']=='nil':\n",
    "            continue\n",
    "        if m['kb_id'] != 'nil':\n",
    "            name_list = [kb[m['kb_id']]['subject']]+kb[m['kb_id']]['alias']\n",
    "            if m['mention'] not in name_list:\n",
    "                continue \n",
    "        candidate_ids = name_id[m['mention']]\n",
    "        for m_candidate_id in candidate_ids:\n",
    "            # 统计配对特征\n",
    "            candidate_numattrs = 0\n",
    "            candidate_abstract_numwords = 0\n",
    "            candidate_detail = kb[m_candidate_id]\n",
    "            candi_text = ''\n",
    "            for predicate in candidate_detail['data']:\n",
    "                candidate_numattrs += 1\n",
    "                candi_text += predicate['object']\n",
    "                #candi_text += predicate['predicate']\n",
    "\n",
    "                if predicate['predicate'] == '摘要':\n",
    "                    candidate_abstract = predicate['object']\n",
    "                    candidate_abstract_numwords = len(candidate_abstract)\n",
    "#                 if predicate['predicate'] == '标签':\n",
    "#                     candidate_label += predicate['object']\n",
    "            if m_candidate_id==m['kb_id']:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            train_column.append(m['mention'])\n",
    "            kb_column.append(m_candidate_id)\n",
    "            text_id.append(s['text_id'])\n",
    "            label_colum.append(label)\n",
    "            m_id_list.append(m_id)\n",
    "            create_works.append('《'+m['mention']+'》' in s['text'] )\n",
    "\n",
    "        m_id += 1\n",
    "        \n",
    "data = pd.DataFrame()\n",
    "data['text_id'] = text_id\n",
    "data['kb_id'] = kb_column\n",
    "data['train_mention'] = train_column\n",
    "data['label'] = label_colum\n",
    "data['m_id'] = m_id_list\n",
    "data['is_works'] = create_works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['deep_match'] = np.load('model_type/deep_match.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据增强应用于deep type和deep cosine\n",
    "# 规则判断type\n",
    "# 句向量距离\n",
    "# jieba词性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ctr = []\n",
    "# kfold = KFold(n_splits=9,shuffle=False,random_state=2019)\n",
    "# for train_index,test_index in kfold.split(data):\n",
    "#     print(test_index)\n",
    "#     stat_train_data,stat_test_data = data.loc[train_index,:],data.loc[test_index,:]\n",
    "#     train_group = stat_test_data.groupby('kb_id',as_index=False)['deep_match'].agg({'kbmatch_mean':'mean',\n",
    "#                                                                                      'kbmatch_max':'max',\n",
    "#                                                                                     'kbmatch_var':'var',\n",
    "#                                                                                      'kbmatch_min':'min'})\n",
    "#     stat_test_data = stat_test_data.merge(train_group,on='kb_id',how='left')\n",
    "#     train_group = stat_test_data.groupby(['kb_id','train_mention'])['deep_match'].agg({'kb_m_match_mean':'mean',\n",
    "#                                                                                         'kb_m_match_max':'max',\n",
    "#                                                                                        'kb_m_match_var':'var',\n",
    "#                                                                                        'kb_m_match_min':'min'})\n",
    "#     stat_test_data = stat_test_data.merge(train_group,on=['kb_id','train_mention'],how='left')\n",
    "#     data_ctr.append(stat_test_data)\n",
    "# data_ctr = pd.concat(data_ctr,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_group = data.groupby('kb_id',as_index=False)['deep_match'].agg({'kbmatch_mean':'mean',\n",
    "#                                                                                      'kbmatch_max':'max',\n",
    "#                                                                                     'kbmatch_var':'var',\n",
    "#                                                                                     'kbmatch_min':'min'})\n",
    "# data = data.merge(train_group,on='kb_id',how='left')\n",
    "# train_group = data.groupby(['kb_id','train_mention'])['deep_match'].agg({'kbm_match_mean':'mean',\n",
    "#                                                                                     'kb_m_match_max':'max',\n",
    "#                                                                                    'kb_m_match_var':'var',\n",
    "#                                                                                    'kb_m_match_min':'min'})\n",
    "# data = data.merge(train_group,on=['kb_id','train_mention'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_group = data.groupby('train_mention',as_index=False)['deep_match'].agg({'m_match_mean':'mean',\n",
    "#                                                                                      'm_match_max':'max',\n",
    "#                                                                                     'm_match_var':'var',\n",
    "#                                                                                     'm_match_min':'min'})\n",
    "# data = data.merge(train_group,on='train_mention',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text_id', 'kb_id', 'train_mention', 'label', 'm_id', 'is_works',\n",
       "       'deep_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank 特征\n",
    "to_rank = ['deep_match'\n",
    "          ]\n",
    "for f in to_rank:\n",
    "    data_group = data.groupby('m_id')[f].rank(ascending=False)\n",
    "    data['mid_rank_'+f] = data_group\n",
    "    try:\n",
    "        data['mid_rank_'+f] = data['mid_rank_'+f].astype('int32')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('data/4_f.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
