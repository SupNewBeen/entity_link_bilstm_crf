{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:u8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy,gc\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm as tqdm\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('features/1_stat_feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>kb_id</th>\n",
       "      <th>train_mention</th>\n",
       "      <th>label</th>\n",
       "      <th>num_attrs</th>\n",
       "      <th>num_abstract_words</th>\n",
       "      <th>num_alias</th>\n",
       "      <th>m_id</th>\n",
       "      <th>num_candidates</th>\n",
       "      <th>mention_equal_subject</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_num_attrs</th>\n",
       "      <th>rank_num_abstract_words</th>\n",
       "      <th>rank_num_alias</th>\n",
       "      <th>rank_label_mean</th>\n",
       "      <th>rank_label_count</th>\n",
       "      <th>rank_m_label_mean</th>\n",
       "      <th>rank_m_label_count</th>\n",
       "      <th>rank_num_candidates</th>\n",
       "      <th>rank_mention_equal_subject</th>\n",
       "      <th>rank_shuminghao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>311223</td>\n",
       "      <td>南京南站</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>447</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>130287</td>\n",
       "      <td>南京南站</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>338</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>213561</td>\n",
       "      <td>高铁</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>341096</td>\n",
       "      <td>高铁</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>311223</td>\n",
       "      <td>南京南站</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>447</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_id   kb_id train_mention  label  num_attrs  num_abstract_words  \\\n",
       "0       1  311223          南京南站      1         17                 447   \n",
       "1       1  130287          南京南站      0          9                 338   \n",
       "2       1  213561            高铁      0          1                   0   \n",
       "3       1  341096            高铁      1         10                 239   \n",
       "4       1  311223          南京南站      1         17                 447   \n",
       "\n",
       "   num_alias  m_id  num_candidates  mention_equal_subject  ...  \\\n",
       "0          3     0               2                   True  ...   \n",
       "1          2     0               2                   True  ...   \n",
       "2          2     1               2                  False  ...   \n",
       "3          1     1               2                   True  ...   \n",
       "4          3     2               2                   True  ...   \n",
       "\n",
       "   rank_num_attrs  rank_num_abstract_words  rank_num_alias rank_label_mean  \\\n",
       "0             1.0                      1.0             1.0          -999.0   \n",
       "1             2.0                      2.0             2.0          -999.0   \n",
       "2             2.0                      2.0             1.0             2.0   \n",
       "3             1.0                      1.0             2.0             1.0   \n",
       "4             1.0                      1.0             1.0          -999.0   \n",
       "\n",
       "   rank_label_count  rank_m_label_mean  rank_m_label_count  \\\n",
       "0            -999.0             -999.0              -999.0   \n",
       "1            -999.0             -999.0              -999.0   \n",
       "2               1.5                2.0                 1.5   \n",
       "3               1.5                1.0                 1.5   \n",
       "4            -999.0             -999.0              -999.0   \n",
       "\n",
       "   rank_num_candidates  rank_mention_equal_subject  rank_shuminghao  \n",
       "0                  1.5                         1.5              1.5  \n",
       "1                  1.5                         1.5              1.5  \n",
       "2                  1.5                         2.0              1.5  \n",
       "3                  1.5                         1.0              1.5  \n",
       "4                  1.5                         1.5              1.5  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictor = ['num_attrs',\n",
    "       'num_abstract_words', 'num_alias', 'num_candidates',\n",
    "       'mention_equal_subject', 'shuminghao', 'len_mention', 'mention_start',\n",
    "       'academicdiscipline', 'animal', 'astronomicalobject', 'athlete',\n",
    "       'awardeventseries', 'brand', 'building', 'collegeoruniversity',\n",
    "       'communicationmedium', 'country', 'creativework', 'culturalheritage',\n",
    "       'currency', 'curriculum', 'educationmajor', 'entertainmentperson',\n",
    "       'event', 'familyname', 'fictionalhuman', 'fictionalthing', 'food',\n",
    "       'formula', 'game', 'historicalperiod', 'historicalperson', 'human',\n",
    "       'internationalorganization', 'language', 'material', 'medicalcondition',\n",
    "       'medicaldepartmenttype', 'movie', 'nation', 'organism', 'organization',\n",
    "       'person', 'place', 'plant', 'product', 'scientificorganization',\n",
    "       'symbol', 'theorem', 'thing', 'tool', 'tvplay', 'tvshow', 'vocabulary',\n",
    "       'zodiacsign', 'label_mean', 'label_count', 'm_label_mean',\n",
    "       'm_label_count', 'rank_num_attrs', 'rank_num_abstract_words',\n",
    "       'rank_num_alias', 'rank_label_mean', 'rank_label_count',\n",
    "       'rank_m_label_mean', 'rank_m_label_count', 'rank_num_candidates',\n",
    "       'rank_mention_equal_subject', 'rank_shuminghao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = []\n",
    "# exclude = []\n",
    "temp = []\n",
    "for x in predictor:\n",
    "    if x not in exclude:temp.append(x)\n",
    "predictor2 = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    #'num_leaves':100,\n",
    "    'objective':'binary',\n",
    "    #'metric':'acc',\n",
    "    'metric_freq':20,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_threads':8,\n",
    "    #'min_sum_hessian_in_leaf':10,\n",
    "    'boosting_type':'gbdt',\n",
    "    'subsample':0.9,\n",
    "    'colsample_bytree':0.8,\n",
    "    'n_estimators':20000,\n",
    "    'min_child_weight':1,\n",
    "    'subsample_freq':2,\n",
    "    'num_leaves':128,\n",
    "    'n_jobs':-1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhukaihua/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[20]\tvalid_0's binary_logloss: 0.157503\tvalid_0's acc: 0.888948\n",
      "[40]\tvalid_0's binary_logloss: 0.105108\tvalid_0's acc: 0.889652\n",
      "[60]\tvalid_0's binary_logloss: 0.0883995\tvalid_0's acc: 0.890919\n",
      "[80]\tvalid_0's binary_logloss: 0.082556\tvalid_0's acc: 0.891904\n",
      "[100]\tvalid_0's binary_logloss: 0.0803302\tvalid_0's acc: 0.892784\n",
      "[120]\tvalid_0's binary_logloss: 0.0793649\tvalid_0's acc: 0.893383\n",
      "[140]\tvalid_0's binary_logloss: 0.0789201\tvalid_0's acc: 0.893629\n",
      "[160]\tvalid_0's binary_logloss: 0.0786494\tvalid_0's acc: 0.893594\n",
      "[180]\tvalid_0's binary_logloss: 0.0784948\tvalid_0's acc: 0.893875\n",
      "[200]\tvalid_0's binary_logloss: 0.0783741\tvalid_0's acc: 0.893981\n",
      "[220]\tvalid_0's binary_logloss: 0.0783051\tvalid_0's acc: 0.894333\n",
      "[240]\tvalid_0's binary_logloss: 0.0781914\tvalid_0's acc: 0.894157\n",
      "[260]\tvalid_0's binary_logloss: 0.0781102\tvalid_0's acc: 0.894263\n",
      "[280]\tvalid_0's binary_logloss: 0.0780461\tvalid_0's acc: 0.894439\n",
      "[300]\tvalid_0's binary_logloss: 0.0779706\tvalid_0's acc: 0.894474\n",
      "[320]\tvalid_0's binary_logloss: 0.0779106\tvalid_0's acc: 0.894791\n",
      "[340]\tvalid_0's binary_logloss: 0.0778661\tvalid_0's acc: 0.89465\n",
      "[360]\tvalid_0's binary_logloss: 0.0777836\tvalid_0's acc: 0.894931\n",
      "[380]\tvalid_0's binary_logloss: 0.0777363\tvalid_0's acc: 0.894896\n",
      "[400]\tvalid_0's binary_logloss: 0.0776933\tvalid_0's acc: 0.895143\n",
      "[420]\tvalid_0's binary_logloss: 0.0776292\tvalid_0's acc: 0.895213\n",
      "[440]\tvalid_0's binary_logloss: 0.0775761\tvalid_0's acc: 0.895424\n",
      "[460]\tvalid_0's binary_logloss: 0.0775521\tvalid_0's acc: 0.895248\n",
      "[480]\tvalid_0's binary_logloss: 0.0775047\tvalid_0's acc: 0.895283\n",
      "[500]\tvalid_0's binary_logloss: 0.0774579\tvalid_0's acc: 0.895248\n",
      "[520]\tvalid_0's binary_logloss: 0.0774338\tvalid_0's acc: 0.895248\n",
      "[540]\tvalid_0's binary_logloss: 0.0774132\tvalid_0's acc: 0.895495\n",
      "[560]\tvalid_0's binary_logloss: 0.0773774\tvalid_0's acc: 0.895459\n",
      "[580]\tvalid_0's binary_logloss: 0.0773615\tvalid_0's acc: 0.895319\n",
      "[600]\tvalid_0's binary_logloss: 0.0773161\tvalid_0's acc: 0.895424\n",
      "[620]\tvalid_0's binary_logloss: 0.0772866\tvalid_0's acc: 0.895635\n",
      "[640]\tvalid_0's binary_logloss: 0.0772778\tvalid_0's acc: 0.895565\n",
      "[660]\tvalid_0's binary_logloss: 0.0772695\tvalid_0's acc: 0.895706\n",
      "[680]\tvalid_0's binary_logloss: 0.0772501\tvalid_0's acc: 0.8956\n",
      "[700]\tvalid_0's binary_logloss: 0.0772185\tvalid_0's acc: 0.895741\n",
      "[720]\tvalid_0's binary_logloss: 0.0771768\tvalid_0's acc: 0.895776\n",
      "[740]\tvalid_0's binary_logloss: 0.0771792\tvalid_0's acc: 0.895706\n",
      "[760]\tvalid_0's binary_logloss: 0.0771532\tvalid_0's acc: 0.895847\n",
      "[780]\tvalid_0's binary_logloss: 0.0771443\tvalid_0's acc: 0.895776\n",
      "[800]\tvalid_0's binary_logloss: 0.077124\tvalid_0's acc: 0.895987\n",
      "[820]\tvalid_0's binary_logloss: 0.0771036\tvalid_0's acc: 0.895987\n",
      "[840]\tvalid_0's binary_logloss: 0.0770684\tvalid_0's acc: 0.896234\n",
      "[860]\tvalid_0's binary_logloss: 0.0770455\tvalid_0's acc: 0.896093\n",
      "[880]\tvalid_0's binary_logloss: 0.0770366\tvalid_0's acc: 0.895917\n",
      "[900]\tvalid_0's binary_logloss: 0.0770325\tvalid_0's acc: 0.895882\n",
      "[920]\tvalid_0's binary_logloss: 0.0770201\tvalid_0's acc: 0.895811\n",
      "[940]\tvalid_0's binary_logloss: 0.0770092\tvalid_0's acc: 0.896163\n",
      "[960]\tvalid_0's binary_logloss: 0.0769728\tvalid_0's acc: 0.895987\n",
      "[980]\tvalid_0's binary_logloss: 0.0769561\tvalid_0's acc: 0.896023\n",
      "[1000]\tvalid_0's binary_logloss: 0.0769266\tvalid_0's acc: 0.896128\n",
      "[1020]\tvalid_0's binary_logloss: 0.0769122\tvalid_0's acc: 0.896339\n",
      "[1040]\tvalid_0's binary_logloss: 0.0768849\tvalid_0's acc: 0.896445\n",
      "[1060]\tvalid_0's binary_logloss: 0.0768651\tvalid_0's acc: 0.896304\n",
      "[1080]\tvalid_0's binary_logloss: 0.0768378\tvalid_0's acc: 0.896339\n",
      "[1100]\tvalid_0's binary_logloss: 0.0768149\tvalid_0's acc: 0.896656\n",
      "[1120]\tvalid_0's binary_logloss: 0.0768117\tvalid_0's acc: 0.896727\n",
      "[1140]\tvalid_0's binary_logloss: 0.0768142\tvalid_0's acc: 0.896832\n",
      "[1160]\tvalid_0's binary_logloss: 0.0767883\tvalid_0's acc: 0.896867\n",
      "[1180]\tvalid_0's binary_logloss: 0.0767849\tvalid_0's acc: 0.897008\n",
      "[1200]\tvalid_0's binary_logloss: 0.0767853\tvalid_0's acc: 0.896762\n",
      "[1220]\tvalid_0's binary_logloss: 0.0767563\tvalid_0's acc: 0.896973\n",
      "[1240]\tvalid_0's binary_logloss: 0.0767416\tvalid_0's acc: 0.897043\n",
      "[1260]\tvalid_0's binary_logloss: 0.0767482\tvalid_0's acc: 0.897149\n",
      "[1280]\tvalid_0's binary_logloss: 0.0767614\tvalid_0's acc: 0.896867\n",
      "[1300]\tvalid_0's binary_logloss: 0.0767682\tvalid_0's acc: 0.896938\n",
      "[1320]\tvalid_0's binary_logloss: 0.0767545\tvalid_0's acc: 0.897078\n",
      "[1340]\tvalid_0's binary_logloss: 0.0767456\tvalid_0's acc: 0.897254\n",
      "[1360]\tvalid_0's binary_logloss: 0.0767492\tvalid_0's acc: 0.897043\n",
      "[1380]\tvalid_0's binary_logloss: 0.0767389\tvalid_0's acc: 0.896832\n",
      "[1400]\tvalid_0's binary_logloss: 0.0767492\tvalid_0's acc: 0.896586\n",
      "[1420]\tvalid_0's binary_logloss: 0.076733\tvalid_0's acc: 0.896797\n",
      "[1440]\tvalid_0's binary_logloss: 0.076738\tvalid_0's acc: 0.896586\n",
      "[1460]\tvalid_0's binary_logloss: 0.0767175\tvalid_0's acc: 0.896621\n",
      "[1480]\tvalid_0's binary_logloss: 0.0767022\tvalid_0's acc: 0.896551\n",
      "[1500]\tvalid_0's binary_logloss: 0.0767072\tvalid_0's acc: 0.896762\n",
      "[1520]\tvalid_0's binary_logloss: 0.0766862\tvalid_0's acc: 0.896938\n",
      "[1540]\tvalid_0's binary_logloss: 0.0766889\tvalid_0's acc: 0.896938\n",
      "[1560]\tvalid_0's binary_logloss: 0.0766878\tvalid_0's acc: 0.896902\n",
      "[1580]\tvalid_0's binary_logloss: 0.0766966\tvalid_0's acc: 0.896762\n",
      "[1600]\tvalid_0's binary_logloss: 0.0767122\tvalid_0's acc: 0.896656\n",
      "[1620]\tvalid_0's binary_logloss: 0.0767042\tvalid_0's acc: 0.896762\n",
      "[1640]\tvalid_0's binary_logloss: 0.0766909\tvalid_0's acc: 0.896797\n",
      "[1660]\tvalid_0's binary_logloss: 0.076692\tvalid_0's acc: 0.896973\n",
      "[1680]\tvalid_0's binary_logloss: 0.0766943\tvalid_0's acc: 0.896832\n",
      "[1700]\tvalid_0's binary_logloss: 0.0766922\tvalid_0's acc: 0.896727\n",
      "[1720]\tvalid_0's binary_logloss: 0.0767127\tvalid_0's acc: 0.896551\n",
      "[1740]\tvalid_0's binary_logloss: 0.0767024\tvalid_0's acc: 0.896515\n",
      "[1760]\tvalid_0's binary_logloss: 0.0766995\tvalid_0's acc: 0.896551\n",
      "[1780]\tvalid_0's binary_logloss: 0.0766833\tvalid_0's acc: 0.896727\n",
      "[1800]\tvalid_0's binary_logloss: 0.076675\tvalid_0's acc: 0.896656\n",
      "[1820]\tvalid_0's binary_logloss: 0.0766678\tvalid_0's acc: 0.896832\n",
      "[1840]\tvalid_0's binary_logloss: 0.0766716\tvalid_0's acc: 0.896867\n",
      "Early stopping, best iteration is:\n",
      "[1344]\tvalid_0's binary_logloss: 0.0767459\tvalid_0's acc: 0.897395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhukaihua/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[20]\tvalid_0's binary_logloss: 0.156436\tvalid_0's acc: 0.889167\n",
      "[40]\tvalid_0's binary_logloss: 0.103792\tvalid_0's acc: 0.889909\n",
      "[60]\tvalid_0's binary_logloss: 0.0870845\tvalid_0's acc: 0.890509\n",
      "[80]\tvalid_0's binary_logloss: 0.0811983\tvalid_0's acc: 0.891427\n",
      "[100]\tvalid_0's binary_logloss: 0.0789214\tvalid_0's acc: 0.892169\n",
      "[120]\tvalid_0's binary_logloss: 0.077979\tvalid_0's acc: 0.892698\n",
      "[140]\tvalid_0's binary_logloss: 0.0774282\tvalid_0's acc: 0.892875\n",
      "[160]\tvalid_0's binary_logloss: 0.0771908\tvalid_0's acc: 0.892804\n",
      "[180]\tvalid_0's binary_logloss: 0.0770143\tvalid_0's acc: 0.893193\n",
      "[200]\tvalid_0's binary_logloss: 0.0768949\tvalid_0's acc: 0.893475\n",
      "[220]\tvalid_0's binary_logloss: 0.0767608\tvalid_0's acc: 0.893616\n",
      "[240]\tvalid_0's binary_logloss: 0.0766801\tvalid_0's acc: 0.89344\n",
      "[260]\tvalid_0's binary_logloss: 0.0765943\tvalid_0's acc: 0.893722\n",
      "[280]\tvalid_0's binary_logloss: 0.0765333\tvalid_0's acc: 0.893404\n",
      "[300]\tvalid_0's binary_logloss: 0.0765101\tvalid_0's acc: 0.893652\n",
      "[320]\tvalid_0's binary_logloss: 0.0764471\tvalid_0's acc: 0.893687\n",
      "[340]\tvalid_0's binary_logloss: 0.0763976\tvalid_0's acc: 0.893828\n",
      "[360]\tvalid_0's binary_logloss: 0.0763519\tvalid_0's acc: 0.893722\n",
      "[380]\tvalid_0's binary_logloss: 0.0763029\tvalid_0's acc: 0.893793\n",
      "[400]\tvalid_0's binary_logloss: 0.0762401\tvalid_0's acc: 0.894111\n",
      "[420]\tvalid_0's binary_logloss: 0.076172\tvalid_0's acc: 0.894287\n",
      "[440]\tvalid_0's binary_logloss: 0.0761028\tvalid_0's acc: 0.894464\n",
      "[460]\tvalid_0's binary_logloss: 0.0760571\tvalid_0's acc: 0.894781\n",
      "[480]\tvalid_0's binary_logloss: 0.0760241\tvalid_0's acc: 0.894534\n",
      "[500]\tvalid_0's binary_logloss: 0.075988\tvalid_0's acc: 0.894428\n",
      "[520]\tvalid_0's binary_logloss: 0.0759826\tvalid_0's acc: 0.89457\n",
      "[540]\tvalid_0's binary_logloss: 0.0759226\tvalid_0's acc: 0.89464\n",
      "[560]\tvalid_0's binary_logloss: 0.0758855\tvalid_0's acc: 0.895029\n",
      "[580]\tvalid_0's binary_logloss: 0.0758654\tvalid_0's acc: 0.895064\n",
      "[600]\tvalid_0's binary_logloss: 0.0758304\tvalid_0's acc: 0.895064\n",
      "[620]\tvalid_0's binary_logloss: 0.0757918\tvalid_0's acc: 0.895382\n",
      "[640]\tvalid_0's binary_logloss: 0.0757803\tvalid_0's acc: 0.895523\n",
      "[660]\tvalid_0's binary_logloss: 0.0757885\tvalid_0's acc: 0.895382\n",
      "[680]\tvalid_0's binary_logloss: 0.0757686\tvalid_0's acc: 0.895417\n",
      "[700]\tvalid_0's binary_logloss: 0.0757637\tvalid_0's acc: 0.895523\n",
      "[720]\tvalid_0's binary_logloss: 0.0757399\tvalid_0's acc: 0.895594\n",
      "[740]\tvalid_0's binary_logloss: 0.0757126\tvalid_0's acc: 0.896017\n",
      "[760]\tvalid_0's binary_logloss: 0.0756942\tvalid_0's acc: 0.895911\n",
      "[780]\tvalid_0's binary_logloss: 0.0756596\tvalid_0's acc: 0.89577\n",
      "[800]\tvalid_0's binary_logloss: 0.0756559\tvalid_0's acc: 0.895982\n",
      "[820]\tvalid_0's binary_logloss: 0.0756554\tvalid_0's acc: 0.89577\n",
      "[840]\tvalid_0's binary_logloss: 0.0756254\tvalid_0's acc: 0.896017\n",
      "[860]\tvalid_0's binary_logloss: 0.0755983\tvalid_0's acc: 0.896123\n",
      "[880]\tvalid_0's binary_logloss: 0.0755609\tvalid_0's acc: 0.896264\n",
      "[900]\tvalid_0's binary_logloss: 0.0755278\tvalid_0's acc: 0.896229\n",
      "[920]\tvalid_0's binary_logloss: 0.075503\tvalid_0's acc: 0.896264\n",
      "[940]\tvalid_0's binary_logloss: 0.0754672\tvalid_0's acc: 0.896653\n",
      "[960]\tvalid_0's binary_logloss: 0.0754579\tvalid_0's acc: 0.896512\n",
      "[980]\tvalid_0's binary_logloss: 0.0754414\tvalid_0's acc: 0.896547\n",
      "[1000]\tvalid_0's binary_logloss: 0.0754087\tvalid_0's acc: 0.896653\n",
      "[1020]\tvalid_0's binary_logloss: 0.075388\tvalid_0's acc: 0.896617\n",
      "[1040]\tvalid_0's binary_logloss: 0.0753831\tvalid_0's acc: 0.896653\n",
      "[1060]\tvalid_0's binary_logloss: 0.0753815\tvalid_0's acc: 0.896688\n",
      "[1080]\tvalid_0's binary_logloss: 0.0753861\tvalid_0's acc: 0.896759\n",
      "[1100]\tvalid_0's binary_logloss: 0.0753692\tvalid_0's acc: 0.896759\n",
      "[1120]\tvalid_0's binary_logloss: 0.0753628\tvalid_0's acc: 0.896582\n",
      "[1140]\tvalid_0's binary_logloss: 0.0753342\tvalid_0's acc: 0.896406\n",
      "[1160]\tvalid_0's binary_logloss: 0.0753247\tvalid_0's acc: 0.896476\n",
      "[1180]\tvalid_0's binary_logloss: 0.0753479\tvalid_0's acc: 0.89637\n",
      "[1200]\tvalid_0's binary_logloss: 0.0753464\tvalid_0's acc: 0.896229\n",
      "[1220]\tvalid_0's binary_logloss: 0.0753223\tvalid_0's acc: 0.896582\n",
      "[1240]\tvalid_0's binary_logloss: 0.0752995\tvalid_0's acc: 0.896829\n",
      "[1260]\tvalid_0's binary_logloss: 0.0753085\tvalid_0's acc: 0.896829\n",
      "[1280]\tvalid_0's binary_logloss: 0.0753024\tvalid_0's acc: 0.8969\n",
      "[1300]\tvalid_0's binary_logloss: 0.0753028\tvalid_0's acc: 0.897324\n",
      "[1320]\tvalid_0's binary_logloss: 0.0753041\tvalid_0's acc: 0.897324\n",
      "[1340]\tvalid_0's binary_logloss: 0.0752987\tvalid_0's acc: 0.897324\n",
      "[1360]\tvalid_0's binary_logloss: 0.0753056\tvalid_0's acc: 0.89743\n",
      "[1380]\tvalid_0's binary_logloss: 0.0753009\tvalid_0's acc: 0.897465\n",
      "[1400]\tvalid_0's binary_logloss: 0.0752888\tvalid_0's acc: 0.897394\n",
      "[1420]\tvalid_0's binary_logloss: 0.0752781\tvalid_0's acc: 0.89743\n",
      "[1440]\tvalid_0's binary_logloss: 0.075266\tvalid_0's acc: 0.896971\n",
      "[1460]\tvalid_0's binary_logloss: 0.0752332\tvalid_0's acc: 0.897182\n",
      "[1480]\tvalid_0's binary_logloss: 0.0752395\tvalid_0's acc: 0.897182\n",
      "[1500]\tvalid_0's binary_logloss: 0.0752313\tvalid_0's acc: 0.897112\n",
      "[1520]\tvalid_0's binary_logloss: 0.0752193\tvalid_0's acc: 0.897288\n",
      "[1540]\tvalid_0's binary_logloss: 0.0752019\tvalid_0's acc: 0.89743\n",
      "[1560]\tvalid_0's binary_logloss: 0.0752137\tvalid_0's acc: 0.897465\n",
      "[1580]\tvalid_0's binary_logloss: 0.0752167\tvalid_0's acc: 0.897571\n",
      "[1600]\tvalid_0's binary_logloss: 0.0752263\tvalid_0's acc: 0.897535\n",
      "[1620]\tvalid_0's binary_logloss: 0.0752074\tvalid_0's acc: 0.897571\n",
      "[1640]\tvalid_0's binary_logloss: 0.0752062\tvalid_0's acc: 0.897783\n",
      "[1660]\tvalid_0's binary_logloss: 0.075205\tvalid_0's acc: 0.897712\n",
      "[1680]\tvalid_0's binary_logloss: 0.0751965\tvalid_0's acc: 0.897747\n",
      "[1700]\tvalid_0's binary_logloss: 0.075214\tvalid_0's acc: 0.89743\n",
      "[1720]\tvalid_0's binary_logloss: 0.0752054\tvalid_0's acc: 0.8975\n",
      "[1740]\tvalid_0's binary_logloss: 0.0752157\tvalid_0's acc: 0.897571\n",
      "[1760]\tvalid_0's binary_logloss: 0.0752181\tvalid_0's acc: 0.897818\n",
      "[1780]\tvalid_0's binary_logloss: 0.0752072\tvalid_0's acc: 0.898065\n",
      "[1800]\tvalid_0's binary_logloss: 0.0751981\tvalid_0's acc: 0.898206\n",
      "[1820]\tvalid_0's binary_logloss: 0.075202\tvalid_0's acc: 0.898065\n",
      "[1840]\tvalid_0's binary_logloss: 0.0752208\tvalid_0's acc: 0.898136\n",
      "[1860]\tvalid_0's binary_logloss: 0.0752214\tvalid_0's acc: 0.898136\n",
      "[1880]\tvalid_0's binary_logloss: 0.0752219\tvalid_0's acc: 0.898065\n",
      "[1900]\tvalid_0's binary_logloss: 0.0752198\tvalid_0's acc: 0.898136\n",
      "[1920]\tvalid_0's binary_logloss: 0.0752272\tvalid_0's acc: 0.898065\n",
      "[1940]\tvalid_0's binary_logloss: 0.0752428\tvalid_0's acc: 0.897889\n",
      "[1960]\tvalid_0's binary_logloss: 0.0752388\tvalid_0's acc: 0.897889\n",
      "[1980]\tvalid_0's binary_logloss: 0.0752481\tvalid_0's acc: 0.897959\n",
      "[2000]\tvalid_0's binary_logloss: 0.0752244\tvalid_0's acc: 0.898136\n",
      "[2020]\tvalid_0's binary_logloss: 0.0751998\tvalid_0's acc: 0.898136\n",
      "[2040]\tvalid_0's binary_logloss: 0.0752158\tvalid_0's acc: 0.897994\n",
      "[2060]\tvalid_0's binary_logloss: 0.0752224\tvalid_0's acc: 0.898136\n",
      "[2080]\tvalid_0's binary_logloss: 0.075217\tvalid_0's acc: 0.897959\n",
      "[2100]\tvalid_0's binary_logloss: 0.0752437\tvalid_0's acc: 0.897853\n",
      "[2120]\tvalid_0's binary_logloss: 0.0752423\tvalid_0's acc: 0.897712\n",
      "[2140]\tvalid_0's binary_logloss: 0.0752513\tvalid_0's acc: 0.897853\n",
      "[2160]\tvalid_0's binary_logloss: 0.0752558\tvalid_0's acc: 0.897994\n",
      "[2180]\tvalid_0's binary_logloss: 0.0752455\tvalid_0's acc: 0.898206\n",
      "[2200]\tvalid_0's binary_logloss: 0.0752407\tvalid_0's acc: 0.898242\n",
      "[2220]\tvalid_0's binary_logloss: 0.0752435\tvalid_0's acc: 0.8981\n",
      "[2240]\tvalid_0's binary_logloss: 0.0752323\tvalid_0's acc: 0.898136\n",
      "[2260]\tvalid_0's binary_logloss: 0.0752458\tvalid_0's acc: 0.89803\n",
      "[2280]\tvalid_0's binary_logloss: 0.0752459\tvalid_0's acc: 0.898171\n",
      "Early stopping, best iteration is:\n",
      "[1794]\tvalid_0's binary_logloss: 0.0751912\tvalid_0's acc: 0.898277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhukaihua/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[20]\tvalid_0's binary_logloss: 0.156043\tvalid_0's acc: 0.88832\n",
      "[40]\tvalid_0's binary_logloss: 0.103511\tvalid_0's acc: 0.889494\n",
      "[60]\tvalid_0's binary_logloss: 0.0866554\tvalid_0's acc: 0.890739\n",
      "[80]\tvalid_0's binary_logloss: 0.0806412\tvalid_0's acc: 0.891415\n",
      "[100]\tvalid_0's binary_logloss: 0.0783448\tvalid_0's acc: 0.891735\n",
      "[120]\tvalid_0's binary_logloss: 0.0773166\tvalid_0's acc: 0.892304\n",
      "[140]\tvalid_0's binary_logloss: 0.0767622\tvalid_0's acc: 0.893087\n",
      "[160]\tvalid_0's binary_logloss: 0.0764993\tvalid_0's acc: 0.893443\n",
      "[180]\tvalid_0's binary_logloss: 0.0763411\tvalid_0's acc: 0.89355\n",
      "[200]\tvalid_0's binary_logloss: 0.0762353\tvalid_0's acc: 0.893728\n",
      "[220]\tvalid_0's binary_logloss: 0.0761553\tvalid_0's acc: 0.893692\n",
      "[240]\tvalid_0's binary_logloss: 0.0760743\tvalid_0's acc: 0.893941\n",
      "[260]\tvalid_0's binary_logloss: 0.0759655\tvalid_0's acc: 0.893977\n",
      "[280]\tvalid_0's binary_logloss: 0.0758895\tvalid_0's acc: 0.894012\n",
      "[300]\tvalid_0's binary_logloss: 0.0758127\tvalid_0's acc: 0.894154\n",
      "[320]\tvalid_0's binary_logloss: 0.0757424\tvalid_0's acc: 0.894439\n",
      "[340]\tvalid_0's binary_logloss: 0.0756901\tvalid_0's acc: 0.89451\n",
      "[360]\tvalid_0's binary_logloss: 0.0756151\tvalid_0's acc: 0.894688\n",
      "[380]\tvalid_0's binary_logloss: 0.0755545\tvalid_0's acc: 0.894795\n",
      "[400]\tvalid_0's binary_logloss: 0.0754938\tvalid_0's acc: 0.894759\n",
      "[420]\tvalid_0's binary_logloss: 0.0754395\tvalid_0's acc: 0.894617\n",
      "[440]\tvalid_0's binary_logloss: 0.0754027\tvalid_0's acc: 0.894866\n",
      "[460]\tvalid_0's binary_logloss: 0.0753755\tvalid_0's acc: 0.895008\n",
      "[480]\tvalid_0's binary_logloss: 0.0753454\tvalid_0's acc: 0.895186\n",
      "[500]\tvalid_0's binary_logloss: 0.0753052\tvalid_0's acc: 0.895186\n",
      "[520]\tvalid_0's binary_logloss: 0.0752793\tvalid_0's acc: 0.895008\n",
      "[540]\tvalid_0's binary_logloss: 0.075226\tvalid_0's acc: 0.894973\n",
      "[560]\tvalid_0's binary_logloss: 0.0752054\tvalid_0's acc: 0.895151\n",
      "[580]\tvalid_0's binary_logloss: 0.0751894\tvalid_0's acc: 0.895364\n",
      "[600]\tvalid_0's binary_logloss: 0.07516\tvalid_0's acc: 0.895435\n",
      "[620]\tvalid_0's binary_logloss: 0.0751202\tvalid_0's acc: 0.89572\n",
      "[640]\tvalid_0's binary_logloss: 0.0750751\tvalid_0's acc: 0.895898\n",
      "[660]\tvalid_0's binary_logloss: 0.0750637\tvalid_0's acc: 0.895613\n",
      "[680]\tvalid_0's binary_logloss: 0.075023\tvalid_0's acc: 0.895933\n",
      "[700]\tvalid_0's binary_logloss: 0.0750225\tvalid_0's acc: 0.895933\n",
      "[720]\tvalid_0's binary_logloss: 0.0750044\tvalid_0's acc: 0.896005\n",
      "[740]\tvalid_0's binary_logloss: 0.0749941\tvalid_0's acc: 0.895898\n",
      "[760]\tvalid_0's binary_logloss: 0.0749591\tvalid_0's acc: 0.896005\n",
      "[780]\tvalid_0's binary_logloss: 0.0749486\tvalid_0's acc: 0.89604\n",
      "[800]\tvalid_0's binary_logloss: 0.0749417\tvalid_0's acc: 0.89636\n",
      "[820]\tvalid_0's binary_logloss: 0.074901\tvalid_0's acc: 0.896182\n",
      "[840]\tvalid_0's binary_logloss: 0.0748769\tvalid_0's acc: 0.896254\n",
      "[860]\tvalid_0's binary_logloss: 0.074839\tvalid_0's acc: 0.89636\n",
      "[880]\tvalid_0's binary_logloss: 0.0748371\tvalid_0's acc: 0.896218\n",
      "[900]\tvalid_0's binary_logloss: 0.0748096\tvalid_0's acc: 0.89604\n",
      "[920]\tvalid_0's binary_logloss: 0.0747977\tvalid_0's acc: 0.896218\n",
      "[940]\tvalid_0's binary_logloss: 0.0747847\tvalid_0's acc: 0.896254\n",
      "[960]\tvalid_0's binary_logloss: 0.0747868\tvalid_0's acc: 0.896254\n",
      "[980]\tvalid_0's binary_logloss: 0.0747984\tvalid_0's acc: 0.896182\n",
      "[1000]\tvalid_0's binary_logloss: 0.0747788\tvalid_0's acc: 0.896289\n",
      "[1020]\tvalid_0's binary_logloss: 0.0747558\tvalid_0's acc: 0.896503\n",
      "[1040]\tvalid_0's binary_logloss: 0.0747492\tvalid_0's acc: 0.896467\n",
      "[1060]\tvalid_0's binary_logloss: 0.0747515\tvalid_0's acc: 0.896538\n",
      "[1080]\tvalid_0's binary_logloss: 0.0747232\tvalid_0's acc: 0.896609\n",
      "[1100]\tvalid_0's binary_logloss: 0.074728\tvalid_0's acc: 0.896609\n",
      "[1120]\tvalid_0's binary_logloss: 0.0747372\tvalid_0's acc: 0.896503\n",
      "[1140]\tvalid_0's binary_logloss: 0.0747051\tvalid_0's acc: 0.896467\n",
      "[1160]\tvalid_0's binary_logloss: 0.0746693\tvalid_0's acc: 0.896609\n",
      "[1180]\tvalid_0's binary_logloss: 0.074646\tvalid_0's acc: 0.896503\n",
      "[1200]\tvalid_0's binary_logloss: 0.0746421\tvalid_0's acc: 0.896431\n",
      "[1220]\tvalid_0's binary_logloss: 0.0746418\tvalid_0's acc: 0.896823\n",
      "[1240]\tvalid_0's binary_logloss: 0.0746057\tvalid_0's acc: 0.896716\n",
      "[1260]\tvalid_0's binary_logloss: 0.0745812\tvalid_0's acc: 0.896858\n",
      "[1280]\tvalid_0's binary_logloss: 0.0745884\tvalid_0's acc: 0.897072\n",
      "[1300]\tvalid_0's binary_logloss: 0.074579\tvalid_0's acc: 0.896965\n",
      "[1320]\tvalid_0's binary_logloss: 0.0745813\tvalid_0's acc: 0.896965\n",
      "[1340]\tvalid_0's binary_logloss: 0.0745744\tvalid_0's acc: 0.897179\n",
      "[1360]\tvalid_0's binary_logloss: 0.074569\tvalid_0's acc: 0.897107\n",
      "[1380]\tvalid_0's binary_logloss: 0.0745526\tvalid_0's acc: 0.897179\n",
      "[1400]\tvalid_0's binary_logloss: 0.0745333\tvalid_0's acc: 0.897072\n",
      "[1420]\tvalid_0's binary_logloss: 0.0745361\tvalid_0's acc: 0.897285\n",
      "[1440]\tvalid_0's binary_logloss: 0.0745325\tvalid_0's acc: 0.897214\n",
      "[1460]\tvalid_0's binary_logloss: 0.0744986\tvalid_0's acc: 0.89725\n",
      "[1480]\tvalid_0's binary_logloss: 0.0744898\tvalid_0's acc: 0.897321\n",
      "[1500]\tvalid_0's binary_logloss: 0.0744632\tvalid_0's acc: 0.897463\n",
      "[1520]\tvalid_0's binary_logloss: 0.0744419\tvalid_0's acc: 0.897641\n",
      "[1540]\tvalid_0's binary_logloss: 0.0744557\tvalid_0's acc: 0.897712\n",
      "[1560]\tvalid_0's binary_logloss: 0.0744621\tvalid_0's acc: 0.897606\n",
      "[1580]\tvalid_0's binary_logloss: 0.0744591\tvalid_0's acc: 0.897677\n",
      "[1600]\tvalid_0's binary_logloss: 0.0744769\tvalid_0's acc: 0.89757\n",
      "[1620]\tvalid_0's binary_logloss: 0.0744714\tvalid_0's acc: 0.897677\n",
      "[1640]\tvalid_0's binary_logloss: 0.0744914\tvalid_0's acc: 0.897499\n",
      "[1660]\tvalid_0's binary_logloss: 0.0744806\tvalid_0's acc: 0.89757\n",
      "[1680]\tvalid_0's binary_logloss: 0.0744824\tvalid_0's acc: 0.897392\n",
      "[1700]\tvalid_0's binary_logloss: 0.0744926\tvalid_0's acc: 0.897357\n",
      "[1720]\tvalid_0's binary_logloss: 0.074498\tvalid_0's acc: 0.89725\n",
      "[1740]\tvalid_0's binary_logloss: 0.0744944\tvalid_0's acc: 0.897321\n",
      "[1760]\tvalid_0's binary_logloss: 0.0744937\tvalid_0's acc: 0.897321\n",
      "[1780]\tvalid_0's binary_logloss: 0.0745106\tvalid_0's acc: 0.897179\n",
      "[1800]\tvalid_0's binary_logloss: 0.0745004\tvalid_0's acc: 0.897036\n",
      "[1820]\tvalid_0's binary_logloss: 0.0744933\tvalid_0's acc: 0.897001\n",
      "[1840]\tvalid_0's binary_logloss: 0.0745034\tvalid_0's acc: 0.896609\n",
      "[1860]\tvalid_0's binary_logloss: 0.074486\tvalid_0's acc: 0.896681\n",
      "[1880]\tvalid_0's binary_logloss: 0.0744865\tvalid_0's acc: 0.896787\n",
      "[1900]\tvalid_0's binary_logloss: 0.0744777\tvalid_0's acc: 0.897072\n",
      "[1920]\tvalid_0's binary_logloss: 0.074486\tvalid_0's acc: 0.897214\n",
      "[1940]\tvalid_0's binary_logloss: 0.0745052\tvalid_0's acc: 0.897285\n",
      "[1960]\tvalid_0's binary_logloss: 0.0745081\tvalid_0's acc: 0.89725\n",
      "[1980]\tvalid_0's binary_logloss: 0.0744961\tvalid_0's acc: 0.897072\n",
      "[2000]\tvalid_0's binary_logloss: 0.0745002\tvalid_0's acc: 0.897143\n",
      "[2020]\tvalid_0's binary_logloss: 0.0744968\tvalid_0's acc: 0.89725\n",
      "Early stopping, best iteration is:\n",
      "[1524]\tvalid_0's binary_logloss: 0.0744377\tvalid_0's acc: 0.897641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhukaihua/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[20]\tvalid_0's binary_logloss: 0.159493\tvalid_0's acc: 0.88686\n",
      "[40]\tvalid_0's binary_logloss: 0.1067\tvalid_0's acc: 0.8881\n",
      "[60]\tvalid_0's binary_logloss: 0.0899887\tvalid_0's acc: 0.889168\n",
      "[80]\tvalid_0's binary_logloss: 0.0840793\tvalid_0's acc: 0.889754\n",
      "[100]\tvalid_0's binary_logloss: 0.0818646\tvalid_0's acc: 0.890546\n",
      "[120]\tvalid_0's binary_logloss: 0.0809254\tvalid_0's acc: 0.890788\n",
      "[140]\tvalid_0's binary_logloss: 0.0804955\tvalid_0's acc: 0.891373\n",
      "[160]\tvalid_0's binary_logloss: 0.0802338\tvalid_0's acc: 0.891442\n",
      "[180]\tvalid_0's binary_logloss: 0.0800739\tvalid_0's acc: 0.891511\n",
      "[200]\tvalid_0's binary_logloss: 0.079954\tvalid_0's acc: 0.89158\n",
      "[220]\tvalid_0's binary_logloss: 0.0798416\tvalid_0's acc: 0.891821\n",
      "[240]\tvalid_0's binary_logloss: 0.0797644\tvalid_0's acc: 0.892131\n",
      "[260]\tvalid_0's binary_logloss: 0.0796862\tvalid_0's acc: 0.8922\n",
      "[280]\tvalid_0's binary_logloss: 0.0796308\tvalid_0's acc: 0.892235\n",
      "[300]\tvalid_0's binary_logloss: 0.0795474\tvalid_0's acc: 0.892338\n",
      "[320]\tvalid_0's binary_logloss: 0.0794858\tvalid_0's acc: 0.892682\n",
      "[340]\tvalid_0's binary_logloss: 0.0794426\tvalid_0's acc: 0.892889\n",
      "[360]\tvalid_0's binary_logloss: 0.0793848\tvalid_0's acc: 0.892751\n",
      "[380]\tvalid_0's binary_logloss: 0.0793295\tvalid_0's acc: 0.892958\n",
      "[400]\tvalid_0's binary_logloss: 0.0792896\tvalid_0's acc: 0.893165\n",
      "[420]\tvalid_0's binary_logloss: 0.0792496\tvalid_0's acc: 0.893234\n",
      "[440]\tvalid_0's binary_logloss: 0.0792015\tvalid_0's acc: 0.892958\n",
      "[460]\tvalid_0's binary_logloss: 0.0791514\tvalid_0's acc: 0.892992\n",
      "[480]\tvalid_0's binary_logloss: 0.0791417\tvalid_0's acc: 0.892924\n",
      "[500]\tvalid_0's binary_logloss: 0.079112\tvalid_0's acc: 0.892682\n",
      "[520]\tvalid_0's binary_logloss: 0.0790978\tvalid_0's acc: 0.892786\n",
      "[540]\tvalid_0's binary_logloss: 0.0790635\tvalid_0's acc: 0.89313\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-493404f91176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     bst = lgb.train(param, train, valid_sets=[validation_data],early_stopping_rounds=500,\n\u001b[0;32m---> 25\u001b[0;31m                     verbose_eval=20,feval=lgb_f1_score)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m#     break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# 0.8672\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks_after_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   1975\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m         \"\"\"\n\u001b[0;32m-> 1977\u001b[0;31m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0m\u001b[1;32m   1978\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1976\u001b[0m         \"\"\"\n\u001b[1;32m   1977\u001b[0m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0;32m-> 1978\u001b[0;31m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m                 \u001b[0mcur_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2375\u001b[0;31m             \u001b[0mfeval_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2376\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_higher_better\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-493404f91176>\u001b[0m in \u001b[0;36mlgb_f1_score\u001b[0;34m(y_hat, data)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mpack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlabel_package\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mhit\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhit\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 4375\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   4376\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=9,shuffle=False,random_state=2019)\n",
    "for train_index,test_index in kfold.split(data):\n",
    "    train_data,val_data = data.loc[train_index,:],data.loc[test_index,:]\n",
    "    train = lgb.Dataset(train_data[predictor2],label=train_data['label'])\n",
    "    validation_data = lgb.Dataset(val_data[predictor2],label=val_data['label'])\n",
    "    \n",
    "    val_data.reset_index(inplace=True,drop=True)\n",
    "    val_data.reset_index(inplace=True)\n",
    "    index_df = val_data.groupby('m_id')['index'].apply(list)\n",
    "    \n",
    "    label_package = val_data.groupby('m_id',as_index=False)['label'].agg({'label_id_max':'idxmax'})['label_id_max']\n",
    "    \n",
    "    def lgb_f1_score(y_hat, data):\n",
    "        y_true = data.get_label()\n",
    "        hit = 0\n",
    "        for index,pack in enumerate(index_df):\n",
    "            score = []\n",
    "            for i in pack:\n",
    "                score.append(y_hat[i])\n",
    "            if pack[np.argmax(score)]==label_package[index]:\n",
    "                hit+=1\n",
    "        best_score = hit/len(index_df)\n",
    "        return 'acc', best_score, True\n",
    "    bst = lgb.train(param, train, valid_sets=[validation_data],early_stopping_rounds=500,\n",
    "                    verbose_eval=20,feval=lgb_f1_score)\n",
    "#     break\n",
    "# 0.8672\n",
    "# 0.872\n",
    "# [171]\tvalid_0's binary_logloss: 0.0988336\tvalid_0's acc: 0.873219\n",
    "# valid_0's binary_logloss: 0.0964686\tvalid_0's acc: 0.87713\n",
    "# [224]\tvalid_0's binary_logloss: 0.096617\tvalid_0's acc: 0.877515\n",
    "# [308]\tvalid_0's binary_logloss: 0.09149\tvalid_0's acc: 0.890507 entity common\n",
    "# drop ctr 0.877\n",
    "# [2094]\tvalid_0's binary_logloss: 0.0791409\tvalid_0's acc: 0.896452\n",
    "# [1674]\tvalid_0's binary_logloss: 0.0784442\tvalid_0's acc: 0.896347\n",
    "#０．９１５"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## for submit  #####################################\n",
    "\n",
    "train = lgb.Dataset(data[predictor2],label=data['label'])\n",
    "param = {\n",
    "    #'num_leaves':100,\n",
    "    'objective':'binary',\n",
    "    #'metric':'acc',\n",
    "    'metric_freq':20,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_threads':8,\n",
    "    #'min_sum_hessian_in_leaf':10,\n",
    "    'boosting_type':'gbdt',\n",
    "    'subsample':0.9,\n",
    "    'colsample_bytree':0.8,\n",
    "    'n_estimators':1000,\n",
    "    'min_child_weight':1,\n",
    "    'subsample_freq':2,\n",
    "    'num_leaves':128,\n",
    "    'n_jobs':-1,\n",
    "}\n",
    "\n",
    "bst = lgb.train(param, train)\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(bst, 'model_link/lgb.pkl')\n",
    "\n",
    "# save model\n",
    "# load model\n",
    "#gbm_pickle = joblib.load('lgb.pkl')\n",
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_importance_df = pd.DataFrame()\n",
    "fold_importance_df[\"feature\"] = predictor2\n",
    "fold_importance_df[\"importance\"] = bst.feature_importance()\n",
    "cols = (fold_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = fold_importance_df.loc[fold_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_importance_df = pd.DataFrame()\n",
    "fold_importance_df[\"feature\"] = predictor2\n",
    "fold_importance_df[\"importance\"] = bst.feature_importance()\n",
    "cols = (fold_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = fold_importance_df.loc[fold_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
