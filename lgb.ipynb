{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:u8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy,gc\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm as tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('features/2_stat_feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_pickle('features/3_stat_feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.read_pickle('data/4_f.pkl').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>kb_id</th>\n",
       "      <th>train_mention</th>\n",
       "      <th>label</th>\n",
       "      <th>num_attrs</th>\n",
       "      <th>num_abstract_words</th>\n",
       "      <th>num_alias</th>\n",
       "      <th>m_id</th>\n",
       "      <th>num_candidates</th>\n",
       "      <th>mention_equal_subject</th>\n",
       "      <th>...</th>\n",
       "      <th>mid_numerical_12_max</th>\n",
       "      <th>mid_numerical_12_min</th>\n",
       "      <th>mid_numerical_13_var</th>\n",
       "      <th>mid_numerical_13_mean</th>\n",
       "      <th>mid_numerical_13_max</th>\n",
       "      <th>mid_numerical_13_min</th>\n",
       "      <th>mid_numerical_14_var</th>\n",
       "      <th>mid_numerical_14_mean</th>\n",
       "      <th>mid_numerical_14_max</th>\n",
       "      <th>mid_numerical_14_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>130287</td>\n",
       "      <td>南京南站</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>338</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.034446</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.031596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>311223</td>\n",
       "      <td>南京南站</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>447</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.034446</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.031596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>341096</td>\n",
       "      <td>高铁</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>130287</td>\n",
       "      <td>南京南站</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>338</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.034446</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.031596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>311223</td>\n",
       "      <td>南京南站</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>447</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.034446</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.031596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 373 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_id   kb_id train_mention  label  num_attrs  num_abstract_words  \\\n",
       "0       1  130287          南京南站      0          9                 338   \n",
       "1       1  311223          南京南站      1         17                 447   \n",
       "2       1  341096            高铁      1         10                 239   \n",
       "3       1  130287          南京南站      0          9                 338   \n",
       "4       1  311223          南京南站      1         17                 447   \n",
       "\n",
       "   num_alias  m_id  num_candidates  mention_equal_subject  ...  \\\n",
       "0          2     0               2                   True  ...   \n",
       "1          3     0               2                   True  ...   \n",
       "2          1     1               1                   True  ...   \n",
       "3          2     2               2                   True  ...   \n",
       "4          3     2               2                   True  ...   \n",
       "\n",
       "   mid_numerical_12_max  mid_numerical_12_min  mid_numerical_13_var  \\\n",
       "0              1.052632              0.842105              0.000016   \n",
       "1              1.052632              0.842105              0.000016   \n",
       "2              0.000000              0.000000                   NaN   \n",
       "3              1.052632              0.842105              0.000016   \n",
       "4              1.052632              0.842105              0.000016   \n",
       "\n",
       "   mid_numerical_13_mean  mid_numerical_13_max  mid_numerical_13_min  \\\n",
       "0               0.034446              0.037296              0.031596   \n",
       "1               0.034446              0.037296              0.031596   \n",
       "2               0.000000              0.000000              0.000000   \n",
       "3               0.034446              0.037296              0.031596   \n",
       "4               0.034446              0.037296              0.031596   \n",
       "\n",
       "   mid_numerical_14_var  mid_numerical_14_mean  mid_numerical_14_max  \\\n",
       "0                   0.0                    0.0                   0.0   \n",
       "1                   0.0                    0.0                   0.0   \n",
       "2                   NaN                    0.0                   0.0   \n",
       "3                   0.0                    0.0                   0.0   \n",
       "4                   0.0                    0.0                   0.0   \n",
       "\n",
       "   mid_numerical_14_min  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "\n",
       "[5 rows x 373 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data2.columns:\n",
    "    if c not in data.columns:\n",
    "        data[c] = data2[c]\n",
    "for c in data3.columns:\n",
    "    if c not in data.columns:\n",
    "        data[c] = data3[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1566680, 464)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('data/final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['text_id',\n",
    " 'kb_id',\n",
    " 'train_mention',\n",
    " 'label',\n",
    " 'm_id','type']\n",
    "# exclude = []\n",
    "temp = []\n",
    "for x in predictor:\n",
    "    if x not in exclude:temp.append(x)\n",
    "predictor2 = temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    #'num_leaves':100,\n",
    "    'objective':'binary',\n",
    "    'metric':'binary_logloss',\n",
    "    'metric_freq':20,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_threads':6,\n",
    "    #'min_sum_hessian_in_leaf':10,\n",
    "    'boosting_type':'gbdt',\n",
    "    'subsample':0.9,\n",
    "    #'xgboost_dart_mode':True,\n",
    "    'colsample_bytree':0.8,\n",
    "    'n_estimators':10000,\n",
    "    'min_child_weight':2,\n",
    "    'subsample_freq':2,\n",
    "    'num_leaves':32,\n",
    "    'n_jobs':-1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1253344, 464) (313336, 464)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhukaihua/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.0745381\n",
      "[200]\tvalid_0's binary_logloss: 0.0708589\n",
      "[300]\tvalid_0's binary_logloss: 0.0700338\n",
      "[400]\tvalid_0's binary_logloss: 0.0696595\n",
      "[500]\tvalid_0's binary_logloss: 0.0693674\n",
      "[600]\tvalid_0's binary_logloss: 0.0692176\n",
      "[700]\tvalid_0's binary_logloss: 0.0690552\n",
      "[800]\tvalid_0's binary_logloss: 0.0689754\n",
      "[900]\tvalid_0's binary_logloss: 0.0688556\n",
      "[1000]\tvalid_0's binary_logloss: 0.0687688\n",
      "[1100]\tvalid_0's binary_logloss: 0.0687191\n",
      "[1200]\tvalid_0's binary_logloss: 0.0686622\n",
      "[1300]\tvalid_0's binary_logloss: 0.0686079\n",
      "[1400]\tvalid_0's binary_logloss: 0.0685624\n",
      "[1500]\tvalid_0's binary_logloss: 0.0685177\n",
      "[1600]\tvalid_0's binary_logloss: 0.0685039\n",
      "[1700]\tvalid_0's binary_logloss: 0.0684775\n",
      "[1800]\tvalid_0's binary_logloss: 0.0684087\n",
      "[1900]\tvalid_0's binary_logloss: 0.0683836\n",
      "[2000]\tvalid_0's binary_logloss: 0.0683697\n",
      "[2100]\tvalid_0's binary_logloss: 0.0683672\n",
      "[2200]\tvalid_0's binary_logloss: 0.0683993\n",
      "Early stopping, best iteration is:\n",
      "[2068]\tvalid_0's binary_logloss: 0.0683592\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5,shuffle=False,random_state=2019)\n",
    "for train_index,test_index in kfold.split(data):\n",
    "    #train_data,val_data = data.loc[train_index,:],data.loc[test_index,:]\n",
    "    train_data,val_data = data.loc[train_index,:],data.loc[test_index,:]\n",
    "    print(train_data.shape,val_data.shape)\n",
    "    train = lgb.Dataset(train_data[predictor2],label=train_data['label'])\n",
    "    \n",
    "    validation_data = lgb.Dataset(val_data[predictor2],label=val_data['label'])\n",
    "    \n",
    "#     val_data.reset_index(inplace=True,drop=True)\n",
    "#     val_data.reset_index(inplace=True)\n",
    "#     index_df = val_data.groupby('m_id')['index'].apply(list)\n",
    "    \n",
    "#     label_package = val_data.groupby('m_id',as_index=False)['label'].agg({'label_id_max':'idxmax'})['label_id_max']\n",
    "\n",
    "    bst = lgb.train(param, train, valid_sets=[validation_data],early_stopping_rounds=200,\n",
    "                    verbose_eval=100)\n",
    "    break\n",
    "\n",
    "    # 观察阈值\n",
    "#     val_data['link_grade'] = bst.predict(val_data[predictor2])\n",
    "#     max_id = val_data.groupby('m_id',as_index=False)['link_grade'].agg({'max_id':'idxmax'})['max_id']\n",
    "#     val_data_temp = val_data.loc[max_id,:]\n",
    "#     # 假设label为１的数据有0.84的概率为真\n",
    "#     m = 0\n",
    "#     n = 0\n",
    "#     hit = 0\n",
    "#     for i in range(100):\n",
    "#         i = i/100\n",
    "#         filter_val = val_data_temp[val_data_temp['link_grade']>i]\n",
    "#         m = filter_val.shape[0]\n",
    "#         n = 28000\n",
    "#         hit = filter_val['label'].mean()*m*0.83\n",
    "#         acc = hit/m\n",
    "#         recall = hit/n\n",
    "#         f1 = 2*acc*recall/(acc+recall)\n",
    "#         print(f1,acc,recall,i)\n",
    "        \n",
    "#０．９１５\n",
    "# [1344]\tvalid_0's binary_logloss: 0.0767459\tvalid_0's acc: 0.897395\n",
    "# [405]\tvalid_0's binary_logloss: 0.0681472\tvalid_0's acc: 0.913129\n",
    "# [1600]\tvalid_0's binary_logloss: 0.0672695\tvalid_0's acc: 0.91415\n",
    "# [2898]\tvalid_0's binary_logloss: 0.0717056\n",
    "# [100]\tvalid_0's binary_logloss: 0.0787558 0.071\n",
    "# [12100]\tvalid_0's binary_logloss: 0.068946 dart\n",
    "# [3476]\tvalid_0's binary_logloss: 0.0705663\n",
    "# [1879]\tvalid_0's binary_logloss: 0.0697744 gbdt\n",
    "# [8200]\tvalid_0's binary_logloss: 0.068178 dart\n",
    "# pure hello [2162]\tvalid_0's binary_logloss: 0.0516024\n",
    "# hello train,data test \n",
    "# [3100]\tvalid_0's binary_logloss: 0.0671858 gbdt\n",
    "# 2737 0.0676\n",
    "# 0.035\n",
    "# 0.0343\n",
    "# 0.0349\n",
    "# [2499]\tvalid_0's binary_logloss: 0.0697551\n",
    "# [2298]\tvalid_0's binary_logloss: 0.0684312\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2068"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.current_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhukaihua/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_data_dart' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-088fb7084974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#import copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbst2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_link/lgb_dart.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data_dart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictor2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_data_dart' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(bst, 'model_link/lgb_dart.pkl')\n",
    "#import copy\n",
    "bst2 = joblib.load('model_link/lgb_dart.pkl')\n",
    "pred2 = bst2.predict(val_data_dart[predictor2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_f1_score(y_hat, data):\n",
    "        y_true = data.get_label()\n",
    "        span = list(np.linspace(0,1, 100))\n",
    "        scores = []\n",
    "        for i in span:\n",
    "            predict_y =  np.where(y_hat >= i, 1,0)\n",
    "            score = f1_score(y_true, predict_y)\n",
    "            scores.append(score)\n",
    "        #print(scores)\n",
    "        best_score = max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = val_data[val_data.pred>0.4]\n",
    "submit = valid_data.groupby('m_id',as_index=False)['pred'].agg({'label_id_max':'idxmax'})\n",
    "m = submit.shape[0]\n",
    "n = sum(val_data.groupby('m_id')['label'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标注错误总结\n",
    "1 非nil标注为nil\n",
    "2 kb_id链接到其他词汇\n",
    "3 可标可不标\n",
    "4 纯粹标注错误\n",
    "label=0 预测偏大 纠正\n",
    "label=1 预测偏小 纠正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.to_pickle('data/old.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_pickle('data/t_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bst.predict(val_data[predictor2])\n",
    "val_data['pred'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = list(np.linspace(0,1, 40))\n",
    "scores = []\n",
    "for i in span:\n",
    "#     predict_y =  np.where(pred >= i, 1,0)\n",
    "#     score = f1_score(val_data['label'], predict_y)\n",
    "#     #print(i,score)\n",
    "#     scores.append(score)\n",
    "#     best_score = max(scores)\n",
    "    n = i\n",
    "    #val_data.loc[(val_data.label_mean>0.99)&(val_data.label_count>10),'pred']=1\n",
    "    valid_data = val_data[(val_data.pred>n)]\n",
    "    #valid_data.loc[(valid_data.label_mean>0.99)&(valid_data.label_count>10),'pred']=1\n",
    "\n",
    "    #valid_data.loc[(valid_data.label_mean==0)&(valid_data.label_count>15),'pred']=0\n",
    "\n",
    "    submit = valid_data.groupby('m_id',as_index=False)['pred'].agg({'label_id_max':'idxmax'})\n",
    "    m = submit.shape[0]\n",
    "    n = sum(val_data.groupby('m_id')['label'].sum())\n",
    "    hit = valid_data.loc[submit['label_id_max'],:]['label'].sum()\n",
    "    print(m,n,hit)\n",
    "    acc = hit/m\n",
    "    recall = hit/n\n",
    "    print(i,acc,recall,2*acc*recall/(acc+recall))\n",
    "# 0.358974358974359 0.9064828744358535 0.9083260297984225 0.9074035161448484\n",
    "# 0.41025641025641024 0.9134305067915026 0.9029272567922875 0.9081485138041677\n",
    "# 0.4358974358974359 0.9561564043528741 0.9456976585764612 0.9508982739050452\n",
    "# 0.1794871794871795 0.8884175317656177 0.8817278302937068 0.8850600402300017\n",
    "# 0.4358974358974359 0.9231731834406925 0.9112650102261912 0.9171804461474181\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = val_data[val_data.pred>0.4]\n",
    "\n",
    "submit = valid_data.groupby('m_id',as_index=False)['pred'].agg({'label_id_max':'idxmax'})\n",
    "val_data['positive'] = 0\n",
    "val_data.loc[submit['label_id_max'],'positive']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = val_data[val_data.positive!=val_data.label][['text_id','kb_id','train_mention','num_candidates','label','label_mean','label_count','m_label_mean','m_label_count',\n",
    "          'cos_distance','rank_cos_distance','pred']]\n",
    "a[a.pred>0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[(a.label_mean>=0.99)&(a.label_count>10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[(val_data.m_label_count>10)&(val_data.m_label_mean==1)&(val_data.positive!=val_data.label)]\\\n",
    "[['text_id','kb_id','train_mention','num_candidates','label','label_mean','label_count','m_label_mean','m_label_count',\n",
    "          'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[(val_data.m_label_count>10)&(val_data.m_label_mean==1)&(val_data.positive!=val_data.label)]\\\n",
    "[['text_id','kb_id','train_mention','num_candidates','label','label_mean','label_count','m_label_mean','m_label_count',\n",
    "          'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[val_data.positive!=val_data.label].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = val_data[val_data.positive!=val_data.label][['text_id','kb_id','train_mention','num_candidates','label','label_mean','label_count','m_label_mean','m_label_count',\n",
    "#           'pred']]\n",
    "# a[a.pred>0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data[['text_id','kb_id','train_mention','label','label_mean','label_count','m_label_mean','m_label_count',\n",
    "#           'cos_distance','rank_cos_distance','pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# span = list(np.linspace(0,1, 100))\n",
    "# scores = []\n",
    "# for i in span:\n",
    "#     predict_y =  np.where(pred >= i, 1,0)\n",
    "#     score = f1_score(val_data['label'], predict_y)\n",
    "#     #print(i,score)\n",
    "#     scores.append(score)\n",
    "# best_score = max(scores)\n",
    "# n = scores.index(best_score)/100\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## for submit  #####################################\n",
    "\n",
    "train = lgb.Dataset(data[predictor2],label=data['label'])\n",
    "param = {\n",
    "    #'num_leaves':100,\n",
    "    'objective':'binary',\n",
    "    'metric':'binary_logloss',\n",
    "    'metric_freq':20,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_threads':6,\n",
    "    #'min_sum_hessian_in_leaf':10,\n",
    "    'boosting_type':'gbdt',\n",
    "    'subsample':0.9,\n",
    "    #'xgboost_dart_mode':True,\n",
    "    'colsample_bytree':0.8,\n",
    "    'n_estimators':4000,\n",
    "    'min_child_weight':2,\n",
    "    'subsample_freq':2,\n",
    "    'num_leaves':64,\n",
    "    'n_jobs':-1,\n",
    "}\n",
    "\n",
    "\n",
    "bst = lgb.train(param, train)\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(bst, 'model_link/lgb.pkl')\n",
    "\n",
    "# save model\n",
    "# load model\n",
    "#gbm_pickle = joblib.load('lgb.pkl')\n",
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features.sort_values(by=['importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['text_id','kb_id','train_mention','label','label_mean','label_count','kbid_rank_label_mean']].sort_values(by='kb_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(data['m_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_importance_df = pd.DataFrame()\n",
    "fold_importance_df[\"feature\"] = predictor2\n",
    "fold_importance_df[\"importance\"] = bst.feature_importance()\n",
    "cols = (fold_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:100].index)\n",
    "\n",
    "best_features = fold_importance_df.loc[fold_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_importance_df = pd.DataFrame()\n",
    "fold_importance_df[\"feature\"] = predictor2\n",
    "fold_importance_df[\"importance\"] = bst.feature_importance()\n",
    "cols = (fold_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = fold_importance_df.loc[fold_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_importance_df = pd.DataFrame()\n",
    "fold_importance_df[\"feature\"] = predictor2\n",
    "fold_importance_df[\"importance\"] = bst.feature_importance()\n",
    "cols = (fold_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = fold_importance_df.loc[fold_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
